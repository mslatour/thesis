%%%%%%%%%%%%%%%%%%%%%
% Chapter: Approach %
%%%%%%%%%%%%%%%%%%%%%
There are several ways to model the task described in
Section~\ref{ch:curriculum_sequencing}. The work presented in this thesis models the
problem using genetic algoritms. Chapter~\ref{ch:background} provides an
introduction into genetic algorithms. This chapter describes the approach used
in this thesis. Each section discusses an important aspect of the modeling: representation
(Section~\ref{sec:approach_representation}), initialization
(Section~\ref{sec:approach_initialization}), termination conditions
(Section~\ref{sec:approach_termination}), fitness
(Section~\ref{sec:approach_evaluation}) and parent selection, variation
operators and survivor selection
(Section~\ref{sec:approach_generation_switch}). The applied island model to
support for related student groups is described in
Section~\ref{sec:approach_island_model}.

\section{Introducing genetic algorithms}
This section provides a brief introduction into genetic algoritms. The purpose
of this section is to establish a shared understanding of the standard setup. For a more
in-depth introduction, the reader is referred to \citep{Eiben2007}.\\\\
\noindent
The \emph{genetic algorithm} \citep{Holland1992} is a part of a family of
search algorithms called \emph{evolutionary computing}. The technique draws
inspiration from Darwinian evolution and naturual selection. In genetic
algorithms, a population of individuals evolves over multiple generations to
better perform on some metric. These individuals all have a set of traits that
influence their performance. For example, a bird could have traits like a long
tail or bright colors. Traits are caused by certain genes. A particular
configuration of genes is called a chromosome. Individuals that perform better
than others have a higher chance of survival. The new generation contains the
offspring of the individuals that survived. The offspring inherits the
chromosomes of their parents. That way, traits that have a positive influence
on performance have a higher chance of ending up in new individuals. Surviving
individuals pair up with others to form a set of two parents. The resulting
offspring inherits a combination of the chromosomes of both parents. Usually
two parents form two new individuals. This application of the \emph{survival of
the fittest} results in more individuals with successful traits and less
individuals with unsuccessful traits.\\\\
\noindent
The peppered moth, the most cited example of Darwinian evolution
\citep{Majerus2009}, illustrates this perfectly. The peppered moth rests during
the day on the trunk of particular trees. At that moment birds pray on the
moths. The color of the peppered moth is originally light gray. This trait
camouflages them fairly well against the light bark of the trees. In other
words, the fitness of these white moths is higher than moths of a different
color. As a result most peppered moths had a light color.
However, that all changed during the industrial revolution. The industrial
revolution caused polution in the air that blackend the bark of the trees. As a
result, the white peppered moths were easily spotted by praying birds. A
variation of the peppered moth, with a dark color, suddenly had a better
camouflage against the dark trunks. The black-bodied peppered moth produced
more offspring because their increased chance of survival. As a result the
occurence of dark peppered moths rose significantly.
In modern times, the air is much cleaner and the color of the bark of the trees
became light again. As a result the dark peppered moths were at a disadvantage.
The frequency of light peppered moths rose to be the large majority once
again.\\\\
\noindent
New variations like the dark peppered moths, are caused by genetic mutations. A
mutation is a copying error of the chromosome during inheritence. The
mutated chromosome causes traits that could benefit an individual's chance of
survival. In that case the mutated chromosome will occur more often in new
generations of the population. As was the case in the example of the peppered
moths.\\\\
The genetic algorithm uses the same approach to find optimal solutions in a
large space of possibilities. In our case, finding the optimal sequence of OER.
A particular application of this algorithm designs counterparts of the
components of the natural selection mechanism. The components that need to be
designed are briefly discussed in the the rest of this section. The standard
genetic algorithm follows roughly the following steps \citep{Eiben2007}.
\begin{leftbar}
\smallskip
\noindent
\textbf{Genetic Algorithm Outline}
\begin{enumerate}
	\item Initialization
	\item Evaluation of each candidate
	\item Repeat until termination condition is satisfied:
		\begin{enumerate}
			\item Parent selection
			\item Recombination of parent pairs
			\item Mutation of the resulting offspring
			\item Evaluation of each candidate
			\item Survivor selection
		\end{enumerate}
\end{enumerate}
\end{leftbar}
\subsection{Representation of the domain}
The \emph{phenotype} is the collection of properties of an individual, such as
a long tail or color. The \emph{genotype} is the genetic information that
causes those properties. In order words, the chromosome containing particular
genes represents the aforementioned properties in genetic terms. This
distinction is important for genetic algorithms, as it is often the case that
there is a translation necessary between the two. Arguably, one of the first
tasks in applying a genetic algorithm is finding an translation of your
solution space to genes.\\\\
\noindent
For example, suppose we want a genetic algorithm to work on the travelling
salesman problem. In this problem, the salesman needs to find the shortest
route through all cities. Each solution to this problem would be some
travelling plan that enumerates cities in the order that the saleman should
visit them \textit{(phenotype)}. This could be encoded as an ordered list of
numbers, where each number represents a city \textit{(genotype)}.
\subsection{Fitness function}
Individuals, carrying a particular chromosome, are exposed to the environment.
This environment determines the chance of survival of the individuals, and
thereby of their chromosomes. In the peppered moth example, the bark of the
tree's trunk determines the survival chance of each individual moth. This
survival chance, due to how well the individual fits its environment, is
expressed by the fitness value. In more abstract terms, the fitness value
expresses how good the found solution is. The fitness function can calculate
these values for an arbitrary individual.\\\\
\noindent
The example of the travelling salesmen has an obvious candidate. The fitness
function could measure the distance travelled in the proposed travelling plan.
Although in this particular example, you would want the distance to negatively
correspond to the survival chance.
\subsection{Population}
A population of individuals goes through several generations. Each generation
is a new step in the search for the optimal solution. The initialization of a
population is usually done by random sampling of chromosomes for its
individuals. An important property is the number of individuals in each
generation. Usually this number is fixed to one number, but it can also vary.
The number of individuals is important as it determines the capacity for
variation in one generation. The population is however a multiset. This means
chromosomes can be contained by multiple individuals. Therefore it is also
relevant to look at the diversity in the generation.\\\\
\noindent
The standard implementation of a genetic algorithm needs to terminate. One
obvious candidate for a termination condition is when the algorithm found an
optimally performing individual. In other words, when the fitness of the
individual is, within a small range of, the maximum possible value. However,
there are no guarantees that the genetic algorithm would reach this point.
Other termination conditions can be added to deal with this. One example is to
stop after a fixed number of evaluations.
\subsection{Evolution}
\label{sec:approach_intro_evolution}
Searching occurs in genetic algorithms by means of evolution. There are three
important stages in this evolution. First parent pairs are selected from the
survivors. The chromosomes of these parents are then recombined into two new
chromosomes. After the recombination, mutation may take place on the resulting
chromosomes. At the end, the two new chromosomes end up in the new generation.
The three stages are further clarified in the next subsections.
\subsubsection{Parent Selection}
When all fitness evaluations have been made, some chromosomes will be selected
to become a parent. Parents are selected in pairs, in order to let their
chromosomes recombinate. This selection of parents is at least based on the
fitness of the chromosomes. However, also other features such as a chromosome's
age may influence the selection. There are also various ways in using these
values for selection. One is \emph{tournament selection}, where individuals
compete against each other and the one with the highest fitness wins. Another
is \emph{ranking selection}, where the probability of a chromosome being
selected is proportionate to its rank in fitness values. A common selection
method is \emph{roulette wheel selection} or \emph{fitness-based selection}.
This is a sampling method where the fitness value is proportionate to the
probability of being sampled. The roulette wheel is a circle divided in a
number of segments. Each segment corresponds to an individual. The size of the
segment is proportionate to the fitness value of the individual. A random
position on the circle is chosen. The segment that contains this position
corresponds to the individual selected.
\subsubsection{Recombination}
Recombination is responsible for combining information from two chromosomes.
This recombination occurs by a crossover operator. There many different
possible crossover operations. Two common ones are \emph{one-point crossover}
and \emph{two-point crossover}. The one-point crossover splits the chromosomes
at the same random point. The resulting four halfs are recombined in the
alternative way, while maintaining their position in the chromosome.
Figure~\ref{fig:single_point_crossover} illustrates the splitting of two parent
chromosomes and their recombination into two child chromosomes.\\
\begin{figure}[h]
	\centering
	\includegraphics[width=0.5\linewidth]{images/single_point_crossover.pdf}
	\caption{Example of a single-point crossover operation}
	\label{fig:single_point_crossover}
\end{figure}\\
\noindent
The two-point crossover splits the chromosomes at two points. The segment of
genes between the two split points in both both chromosomes is swapped.
Figure~\ref{fig:two_point_crossover} illustrates the application of the
two-point crossover.\\
\begin{figure}[h]
	\centering
	\includegraphics[width=0.5\linewidth]{images/two_point_crossover.pdf}
	\caption{Example of a two-point crossover operation}
	\label{fig:two_point_crossover}
\end{figure}%\\
%\noindent
%Schema theorem\ldots
\subsubsection{Mutation}
Selection and recombination steer the search towards the part of the search
space that appears to be most promising. As a result, parts of the search space
might never be reached and evaluated. There is no guarantee that this steering
will converge to an optimal solution. This is especially true when the initial
population does not hold the necessary variation. Therefore, most genetic algorithm
implementations also include mutation. The mutation operator introduces random
changes to chromosomes when passed through from parents to offspring. In the
standard binary encoding of genes in a chromosome, the basic mutation operator
flips a random bit.\\\\
\noindent
Although mutations can be vital for performance, it is still a disruption. Too
much mutation will prevent convergence. Mutation is therefore usually only
applied with a very low probability. The mutation operator is applied after
recombination took place.
\subsubsection{Survivor selection}
Populations often have a fixed size. The newly created offspring together with
the existing population forms a group of candidates that exceeds this size. In
the survivor selection step, the members of the new generation are selected
from these candidates. Unlike the parent selection, which is stochastic, the
survivor selection is often deterministic. An example selection method is to
just take the top $n$ chromosomes in order of their fitness. Another common
method is \emph{generational replacement}. In this method, the chromosomes in
the generation are completely replaced by their offspring.
\subsection{Extensions}
Several extensions have been proposed to the standard genetic algorithm. Two of
them are relevant for this thesis. They will be briefly explained.
\subsubsection{Elite preservation}
Although mutation ensures that every chromosome is theoretically reachable.
However, the probability of this happening might be very small. In a finite
number of generations there is no guarantee that the optimal solution will be
found. There is furthermore no guarantee that good solutions will be kept in
the population. Elitism, or \emph{elite preservation}, ensures that the $n$
best individuals of each generation are transferred to the next one. Elite
individuals are not subjected to crossovers or mutation. Nor are they dependant
on stochastic sampling. The number of elite individuals must be kept small.
Otherwise the genetic algorithm will no longer have enough individuals to evolve.
\subsubsection{Island model}
In the island model, a population is split up in separate subpopulations,
called \emph{demes}. These demes evolve independantly from each other.
However, periodically communication can occur through \emph{migration} of
individuals. The approach is a form of parallelisation and works particularly
well when a problem consists of linearly separable subproblems
\citep{Whitley1999}.\\\\
\noindent
According to \citep{Nowostawski1999}, the island model is controlled by
four parameters. These are the \emph{topology}, the \emph{migration interval}, the
\emph{migration scheme} and the \emph{migration size}. The \emph{topology}
determines which demes are connected, which allows for migration. The
\emph{migration interval} determines the number of generations between a
migration. The \emph{migration scheme} determines which individual is picked
from the source deme: the worst, the best or a random individual. It also
determines which individual is replaced at the target deme: the worst, the best
or a random individual. Replacement only occurs if the migrating individual has a higher fitness. The \emph{migration size} determines how many individuals are
exchanged during each migration. For a more extensive analysis of the island model in genetic algorithms the reader is referred to \citep{Martin1997} and \citep{Whitley1999}.

%%%%
% Representation/Domain modeling
%%%
\section{Representation of the domain}
\label{sec:approach_representation}
In this thesis, each OER is encoded as a single gene. A
chromosome represents a particular sequence of resources. The order of the
genes in the chromosome, determines the order in which the material is presented to
the student. Each knowledge component and student group combination is represented
by a separate population. The populations related to a single knowledge
component are linked in an island model.
Section~\ref{sec:approach_island_model} discusses this. There are no links
between populations of different knowledge components. They evolve
independently from each other.\\\\
\noindent
The length of the optimal sequence of OER is not known apriori. To cope with
that, chromosomes have variable length. This length will be
bounded to a lower and upper limit for practical reasons. The encoding of the
sequence must support the variable length. To support this, a chromosome is
encoded as a list of gene identifiers (i.e. integers).  There are two main
arguments for choosing this encoding over the standard binary encoding.
First, the mutation and crossover operations defined in Section~\ref{sec:approach_combination_operator}
and Section~\ref{sec:approach_mutation_operator}
take the educational resource as smallest unit. In applications that use the
standard binary encoding it is common to operate on a bit level. The boundaries
of each gene in the binary representation is often not respected. However, the
number of OER is relatively low compared to the capacity of its binary
encoding. As a consequence, many illegitimate chromosomes would be generated.
Second, the application created in this thesis is web-based. Storing and
manipulating chromosomes happens in a relational database. Encoding each
chromosome as a list of gene identifiers is easier optimized for the
implementation.

%%%
% Initialization
%%%
\section{Initialization}
\label{sec:approach_initialization}
The first generation of the population is initialized with a fixed number of
individuals. Each individual contains a chromosome with exactly one gene. The
individuals are generated according to the following steps:
\begin{enumerate}
	\item For all genes in pool:
		\begin{enumerate}
			\item If population is full, stop
			\item Else, add an individual with the chromosome that contains only that gene.
		\end{enumerate}
	\item While there is room left in the population:
		\begin{enumerate}
			\item \label{init_sample_step}Select a gene according to some probability density function
			\item Add an individual with the chromosome that contains only that
				gene
		\end{enumerate}
\end{enumerate}
The probability density function (PDF) refered to in
step~\ref{init_sample_step} is a uniform distribution by default, but can also
represent apriori values of resources as proposed in
Chapter~\ref{ch:future_work}.
%%%
% Termination
%%%
\section{Termination}
\label{sec:approach_termination}
Given the inherent noise in the fitness values, the algorithm should not stop
before the fitness of each possible\footnote{i.e. all possible sequences given
the constraints on length and the uniqueness requirement} chromosome is determined
with some certainty. That would seem to lead to a valid point of termination
when all chromosomes are tried are evaluated with enough certainty. However,
the pool of genes is assumed to grow (i.e. new educational resources are made
available) and each time a new gene is introduced it theoretically needs to be
tried out in every combination with the already existing genes before the valid
termination point would be reached. This would mean that the algorithm would
never terminate, as it should wait for new genes to arrive. If it is vital that
the algorithm finishes, a practical approach could be to stop if the fitness of
one or more individuals is within a small margin of the optimal value. Provided
an optimal value can be defined.\\\\
\noindent
The application presented in this thesis does not require the genetic algorithm
to terminate. The web-based variation to the algorithm described in
Section~\ref{sec:web-based_ga} ensures that computation only happens on a event
basis. Furthermore, due to the nature of the application, it is not
as interesting to have the best solution at the end as it is to select the best
known solution at each point that an individual is tested. Naturally a
exploration-explotation trade-off applies where occassionally individuals need
to be tried out that could both be better or worse. So instead of termination,
moving towards convergence is important.

%%%
% Candidate evaluation
%%%
\section{Candidate evaluation}
\label{sec:approach_evaluation}
%%%
% 	Fitness function
%%%
\subsection{Fitness function}
% From: A comprehensive survey of fitness approximation
%  in evolutionary computation. By: Y. Jin (2005)
% Chen J-H, Goldberg DE, Ho S-Y, Sastry K (2002) Fitness
%  inheritance in multi-objective optimization.
% Sastry K, Goldberg DE, Pelikan M (2001) Don’t evaluate,inherit.
% Smith R, Dike B, Stegmann S (1995) Fitness inheritance in
%  genetic algorithms
% Zhang X, Julstrom B, Cheng W (1997) Design of vector
%  quantization codebooks using a genetic algorithm
Learning objects are often not a perfect fit. They might explain too much or too
little about some context. On top of that, it is not that well indexed in terms of the
exact type of presentation that they have. Thus, what we want is a
sequence of imperfect learning objects that together maximize the
educational performance. We do not know what the order should be, given
that the order is a matter of pedagogy and not knowledge engineering.
And even if we were able to fully specify the right pedagogical order
for each type of student perfectly. We would still not have the
required information about these learning objects, or the information
might be wrong. In conclusion, we are learning a sequence of black
boxes of which we only know that they attempt to teach a particular
knowledge component.\\\\
\noindent
The only way we can measure the value of a particular sequence for a
group of students, and thereby assess its fitness, is to look at the
gain in knowledge as observed by the post-test. More precisely the fitness
function used in this thesis is the normalized learning gain between the
pre-test and post-test for a given knowledge component, given by $\frac{C^2 -
C^1}{1-C^1}$ where $C^1$ and $C^2$ represent the percentage of correct answers
on the pre-test and post-test respectively of the student.\\\\
\noindent
The observed fitness is probably not the same each time a chromosome
is evaluated. This is due to the fact that students are not identical,
especially not given the coarse division into student groups. A solution
is to see the fitness as a stochastic variable that has some noise on
top of the ``true'' value. In order to obtain an estimate of this true
value, several approaches are possible. The most simple one is to take
multiple samples and average over them. However, in this case, taking
samples must be considered to be expensive. The approach taken must
therefore try to minimize the number of samples while maximizing the
certainty of the fitness value. Which is why Upper Confidence Bound selection
was applied in this thesis, as described in Section~\ref{sec:approach_ucb}.

%%%
%   UCB-1 selection
%%%
\subsection{UCB Selection}
\label{sec:approach_ucb}
The consequence of having a fitness function that involves actual
students is that the event of evaluating a suboptimal individual
also causes damage to the learning process of the student. Something
which is much less the case in a simulation environment.\\\\
\noindent
In the reinforcement learning paradigm this damage is expressed in regret, which
is defined as the difference in performance with the choice made and the
optimal choice. You do however need to evaluate all individuals to see if one
scores better. You even need to evaluate each individual several times in order
to deal with outliers and varience. However you don't want to evaluate an
individual too often when you know it performs suboptimally, given the regret
it will cause. This is a classic exploration vs. exploitation trade-off that is
found in any one-armed bandit problem, where in this application the sequences
of educational material are the one-armed bandits.\\\\
\noindent
In this thesis, the Upper Confidence Bound (UCB) selection algorithm is used to
determine which of the individuals will be evaluated. In
particular the UCB-1 \citep{Auer2002} algorithm is used. In UCB-1,
first every individual is evaluated once. After this has been done, the
individual is evaluated for which equation~\eqref{eq:ucb1_value} is maximized,
where $\overline{x_i}$ denotes the average fitness of the individual, $n_i$
denotes the number of times the individual has been evaluated so far and $n$
denotes the overal number of evaluations that occured.

\begin{equation}
	\overline{x_i} + \sqrt{\frac{2 \ln n}{n_i}}
	\label{eq:ucb1_value}
\end{equation}
\noindent
UCB-1 is proven in \citep{Auer2002} to logarithmically bound the
regret, which ensures that a suboptimal individual is selected logarithmically
less often than the optimal individual. It is important to note that UCB-1 can
only consider the individuals that are present in the current generation of the
population for which the evaluation occurs. This means that there is some
interplay between the UCB-1 mechanism and the selection mechanism of the
genetic algorithm, where the genetic algorithm is responsible for searching
through the solution space efficiently and the UCB-1 algorithm is responsible
for reducing the regret.

%%%
% Generation switch
%%%
\section{Generation switch}
\label{sec:approach_generation_switch}
\begin{figure}[ht!]
	\centering
	\includegraphics[width=0.8\linewidth]{images/generation_switch.png}
	\caption[Generation switch]{The operations and intermediate phases during a generation switch. Illustration was taken from \citep{Whitley1994}.}
	\label{fig:generation_switch}
\end{figure}
This thesis implements generational replacement with elite preservation, which
are commonly used strategies for survivor selection in the curriculum
sequencing domain \citep{AlMuhaideb2011}.
Elite preservation means that the best performing individuals from the current
generation will transfered directly to the new generation, without any
alteration. Elitism has the purpose of ensuring that cross-over or mutation
operators cannot push the evolution away from what was most promising.
Only when better candidates are found will the elite individual not necessarilly survive.

Generational replacement refers to the strategy where the number of individuals
in the new generation remains the same as in the current generation. The
individuals in the new generation are different individuals\footnote{The new
generation  could still contain the same chromosomes.} than those in the
current generation, with the exception of the elite individuals.

The individuals of the new generation are created in two steps, as is depicted
by Figure~\ref{fig:generation_switch}. First surivors are selected from the
current generation and put in an intermediate generation, which is described in
Section~\ref{sec:approach_survivor_selection}. The survivors are then grouped
into parent pairs, as discussed in
Section~\ref{sec:approach_parent_selection}.
Section~\ref{sec:approach_combination_operator} describes how these parents
then produce offspring by combining the chromosomes of both parents. In
Section~\ref{sec:approach_mutation_operator} the mutation operations that
can occur are described.

%%%
% 	Survivor selection
%%%
\subsection{Survivor selection}
\label{sec:approach_survivor_selection}
In this thesis, survivors are selected from the current generation using the
roulette wheel selection. In this selection strategy, each individual from the
current generation is assigned a portion of a roulette wheel, proportionate to
the normalized fitness of the individual in the current generation. A survivor
is then sampled by uniformly picking a position on the wheel and selecting the
the individual to who that spot on the wheel was assigned to. This is analogous
to spinning the roulette wheel perfectly. The higher the fitness of the
individual, the bigger the area on the roulette wheel and thereby also the more
likely the individual will survive. A individual can be selected multiple
times, with the consequence that some individuals might not survive.

Due to the normalization of the fitness values, the roulette wheel selection
is implemented in three steps. First, take a random number between zero and one.
Second, loop through all individuals until the cumulative fitness is bigger
than the random number. Third, the last individual in the loop is selected as
survivor.

%%%
%  	Parent selection
%%%
\subsection{Parent selection}
\label{sec:approach_parent_selection}
Pairs of individuals are taken from the list of survivors, excluding the elite
individuals, from top to bottom. That means that parents are matched based on
the order that they were selected in the roulette wheel selection described in
Section~\ref{sec:approach_survivor_selection}. The pairing is also shown in
Figure~\ref{fig:generation_switch}. Each parent pair results in offspring
based on the crossover operations described in
Section~\ref{sec:approach_combination_operator}. If the number of survivors is
odd, there will be one suvivor remaining after all pairs have been formed.
This remaining survivor's chromosome is added to the new generation
as its own offspring.

%%%
%  	Crossover operation
%%%
\subsection{Combination operator}
\label{sec:approach_combination_operator}
When two parents are matched to create offspring, their chromosome's are
combined using a crossover operation. The resulting chromosome is placed in a
new individual. There are two crossover operations implemented for this thesis:
\emph{one-point crossover} and \emph{append crossover}.

\paragraph{One-point crossover} The one-point crossover operation is typically
implemented by picking one point for both parents to split, after which the
four halfs are recombined into two new children. The individuals in this
thesis, however, can vary in length. That means that crossover points could be
selected that do not exist in both parents. Naturally one could restrict the
set of valid crossover points to be within the boundaries of both chromosomes.
However, that would also limit valid chromosomes, even though they can be
achieved by combining both parent chromosomes.

In this thesis, the one-point crossover operator is implemented differently.
Instead of picking one point for both parents at once, one crossover point in
each parent is randomly picked independent from the other. These two crossover
points then split up both parents in two pieces each, allowing for the
formation of two new children after recombination. The implementation ensures
that only valid children are the result of the operation. When no valid
children can be created, the one-point crossover is skipped and the append
crossover is attempted.

\paragraph{Append crossover} The append crossover was designed for the edge
case where two parents cannot be split up and recombined into two new valid
children. For example when one or both parents have a chromosome with one gene,
which is impossible to split up. The append crossover operator simply appends
one parent after the other. The two ways to do this result in two children.

%%%
%  	Mutation operation
%%%
\subsection{Mutation operator}
\label{sec:approach_mutation_operator}
Most of the mechanism in genetic algorithms ensures that individuals in each
generation are samples from increasingly smaller areas in the solution
hyperspace. This has the effect that large parts of that hyperspace is never
evaluated. To prevent that from limiting the genetic algorithm to local optima,
the mutation operator is used. After the chromosomes in the offspring are
determined using the crossover operation, each child's chromosome has a small
chance of mutation. In this thesis three different mutation operators have been
applied: \emph{swap mutation}, \emph{addition mutation}, \emph{deletion mutation}.

\paragraph{Swap mutation} The swap mutation operation randomly picks two
distinct genes in a chromosome that are swapped. The chromosome needs to
contain at least two genes in order to be applied to this mutation. If this is
not the case, a different mutation is attempted.

\paragraph{Addition mutation} The chromosome applied to the addition mutation
operator will be appended with a new gene from the gene pool. The gene that is
added must not already exist in the chromosome. If no gene can be selected from
the pool that satisfies this constraint, a different mutation is attempted.

\paragraph{Deletion mutation} The deletion mutation operation deletes a random
gene from the chromosome, resulting in a shift in position of the genes after
it. The resulting chromosome must have at least one gene left. If this is not
possible, a different mutation is attempted.

%%%
% Island model
%%%
\section{Island model}
\label{sec:approach_island_model}
As described in Section~\ref{sec:approach_representation}, the curriculum
sequencing problem is done per knowledge component and per student group. These
are represented as separate populations. However, the populations that
represent the same knowledge component but different student groups actually
co-evolve. The island model was used to model exchange of information between
related populations. After each generation of a population, the best
individuals from the other related populations can migrate towards this
population, replacing the worst individual. The migrated individuals are
copies, and do not change the occurrence of the migrated chromosomes in the
originating populations.

Important to note is that all other actions of the genetic algorithm in each
population are still independent, meaning that the populations can also evolve
at different speeds. One reason for this would be that the distributions of
students in each student group will not be uniform. That has the consequence
that a population that evolves really slowly will continue to migrate the same
individual towards the other population. Even if it turned out not to work
well. To counter this, the immigrants compete with the worst individual in
roulette selection. This means that if the immigrants are a lot worse than the
worst individual of this population, the worst individual is likely to remain
in the population.

The idea behind applying the Island model on this task is that what seems to work
extremely well for one student group, might also be close to a good solution in
other student groups. If there are more student groups than two, there are more
migration candidates than slots. In that case, the choice is made using
roulette wheel selection based on the fitness values of each migration
candidate.
