%%%%%%%%%%%%%%%%%%%%%
% Chapter: Approach %
%%%%%%%%%%%%%%%%%%%%%
\label{ch_approach}
There are several ways to model the educational task described in
section~\ref{ch_problem_domain}. The work presented in this thesis models the
problem using genetic algoritms. Two other modeling choices that are common for
this problem are markov decision processes and knowledge-based systems.
Section~\ref{approach_discussion} discusses the disadvantages of using genetic
algorithms as a model and compares it with the two alternative modeling
choices. First, section~\ref{approach_genetic_algorithm} describes the details
of the genetic algorithm modeling.
\section{The Genetic Algorithm approach}
\label{approach_genetic_algorithm}
\begin{figure}[ht!]
	\begin{framed}
		\begin{enumerate}
			\item Initialization
			\item Evaluation of each candidate
			\item Repeat until termination condition is satisfied:
				\begin{enumerate}
					\item Parent selection
					\item Recombination of parent pairs
					\item Mutation of the resulting offspring
					\item Evaluation of each candidate
					\item Survivor selection
				\end{enumerate}
		\end{enumerate}
	\end{framed}
	\caption[The evolutionary algorithm]{The general scheme of an
		Evolutionary Algorithm as presented in \citep{Eiben2007}}
	\label{alg:ea_scheme}
\end{figure}
\begin{itemize}
	\item refer to \ref{alg:ea_scheme}.
	\item refer to \citep{Eiben2007} for listing the important aspects of any evolutionary algorithm that need to be modeled: representation, fitness, population, parent selection, variation operators, survivor selection, initialization and termination conditions
\end{itemize}
\subsection{Island model}
\begin{figure}[ht!]
	\centering
	\includegraphics[scale=0.7]{images/group_dimensions.pdf}
	\caption[Group characterization]{Students are characterized in four groups.
		The horizontal axis represents the pre-test score, the vertical axis
		the relevant prior experience.}
	\label{fig:group_dimensions}
\end{figure}
\begin{figure}[ht!]
	\centering
	\includegraphics[width=0.5\linewidth]{images/neighborhood_migration_topology.pdf}
	\caption[Neighborhood Migration Topology]{}
	\label{fig:migration_topology}
\end{figure}
\begin{itemize}
	\item Each student is characterized by two dimensions
		\begin{itemize}
			\item score on the pre-test for this particular knowledge component
			\item relevant experiences
		\end{itemize}
	\item Other things that could have been included are learning
		style, gender and age. As is also common in most user models in
		curriculum sequencing applications. However, in this thesis it
		was decided not to include those. Partly because of the
		difficult way some of the indicators can be retrieved or
		checked automatically, as is for example difficult for learning
		style. And partly because it would enlarge the state space even
		more.
	\item The two dimensions are discretized into two values, high and low.
	\item This results in four categories:
		\begin{description}
			\item[A] This person has a lot of relevant experience but did not
				score well on this particular knowledge component in the
				pre-test.
			\item[B] This person has a lot of relevant experience and also
				scored high on the pre-test for this knowledge component.
			\item[C] This person has neither much relevant experience nor
				a high score on the pre-test for this knowledge component.
			\item[D] This person does not have a lot of relevant experience,
				but did score high on the pre-test on this knowledge component.
		\end{description}
	\item The four categories are also depicted in figure~\ref{fig:group_dimensions}.
	\item The curriculum sequencing problem is splitted up per student group,
		while maintaining the ability for good solutions to be copied.
		Analogous to a teachter that teaches in different grades, the algorithm
		tries to optimize the learning material for each group separately. But
		in that same analogy, if the teacher would see that a particular
		approach would work really well for one group he might be inclined to
		try it out on the other groups as well. The underlying assumption is
		that there are some universal do's and don'ts for the explanation of
		the same topics, some examples work better than others etc. The student
		groups, although different on a few selected dimensions, are likely to
		be similar on many other dimensions.
	\item This results in solving separate tutoring problems that are not
		independant, and thereby could benefit exchange of solutions.
	\item Each distinct student group is modelled by an island, see
		Figure~\ref{fig:migration_topology}
	\item Each island has its own independant evolution
	\item The genetic algorithm implementation is identical for each island
	\item But because fitness is only observed by student experience and that
		it depends on which type of student participates which island will
		evaluate an individual, it is likely that the islands will have
		different speeds of generation iterations.
	\item Migration (ie. copy) can occur of the best individual of one island
		to replace the worst individual of the next island.
	\item Migration only takes place between adjacent islands, which is defined
		as islands that only differ on one dimension and with one value step,
		in other words a vector distance of 1.
	\item When multiple adjacent islands exist to receive a best individual
		from, only one will replace the worst one of the population. The
		selection is done probabilistically based on the fitness functions of
		each migration candidate.
	\item Migration occurs after each generation
\end{itemize}
\subsection{Encoding}
Genetic algorithms evolve a population of individuals. An individual contains a
chromosome that represents a candidate solution. A particular chromosome can be contained by
multiple individuals, and as such a candidate solution can be present multiple
times in one generation of the population. Chromosomes are a configuration of
genes, where each gene represents a component of the candidate solution. In the
analogy with natural evolution these genes typically represent certain traits
of the animal, such as the length of wings or the color, that affect the change
of survival and can be optimized by inheritence and natural selection.

In this thesis, each educational resource is encoded as a single gene. A
chromosome represents a particular sequence of resources. The order of these
resources in the sequence matter, which is not often the case in genetic
algorithm applications, as it determines in what order material is presented to
the student. An individual denotes a particular teaching attempt where a particular
sequence of the education resources is presented to a student.

It is not known apriori what the length of the optimal sequence of material is,
which means that chromosomes have variable length. For practical reasons this
length will be bounded to a lower and upper limit in the application. 

Instead of using the standard binary encoding (i.e. the binary representations
of all genes concatenated into one string of bits), a chromosome is encoded as a list
of gene identifiers (i.e. integers). There are two main arguments for this decision.
First, the operations defined in sections~\ref{sec:approach_combination_operator}~and~\ref{sec:approach_mutation_operator}
take the educational resource as smallest unit. In applications that use the
standard binary encoding it is common to operate on a bit level, regardless of
the start and finish of each gene representation. Second, the application
created in this thesis which applies this genetic algorithm model is web-based
and uses relational databases to store the chromosomes. The genetic operations
are implemented to work with these database entities and consist largely of
database queries. This combined with the fact that the chromosome has variable
length requires a many-to-many relation between separate chromosome and gene
entities. The alternative of storing a bit string for each chromosome defeats
the purpose of having a database optimized for relational algebra.

%There should be a bias towards smaller chromosomes.

% TODO: update
%\subsubsection{The sequence chromosome}
%\begin{figure}[h!]
%	\centering
%	\includegraphics[scale=0.6]{images/concept_hierarchy2.pdf}
%	\caption[Components of the chromosome]{Components of the chromosome}
%	\label{fig:chromosome_components}
%\end{figure}
%\begin{itemize}
%	\item Refer to Figure~\ref{fig:chromosome_components}.
%	\item The chromosome contains exactly one group gene
%\end{itemize}
\subsection{Fitness function}
\begin{itemize}
	\item evaluation function and fitness function are not by definition
		interchangeable. The evaluation function, or objective function,
		provides a measure of performance. The fitness function transforms this
		into reproductive opportunities. Unline the evaluation function, the
		fitness function is defined with respect to the fitness of the other
		members in the population. From: \citet{Whitley1994}. (Paraphrase
		this!) In other words, the fitness function is at least a normalized
		version of the evaluation function obtained by dividing by the average
		fitness value of the current population/generation.
	\item The literature contains many different implementations of fitness
		functions for the curriculum sequencing problem. 
	\item Some solutions include a term that expresses how well a particuluar
		solution fits the pre-determined prerequisite structure of the learning
		objects. Others include a term that expresses how smooth the transitions
		are between learning objects in difficulty.
	\item A big part of the prerequisite structure is already captured by the
		given main curriculum in this thesis that provides the order of
		knowledge components. The curriculum sequencing step takes place
		in this thesis on a much smaller level where the different learning
		objects all try to convey the same content, but do so in different
		ways. In a way this means that this thesis implements a particular type
		of curriculum sequencing that focuses on the presentation. Some objects
		might contain an example or the formal description. Some might present
		the knowledge in text, others are more visual. Yet it is not expected
		to need only one learning object per student, if you would consider
		the learning object term referring to the smallest unit of explanation.
		Different students require a different mix of presentations at perhaps
		even different orders. Furthermore, learning objects are often not
		a perfect fit. They might explain too much or too little about some
		context. On top of that, it is not that well indexed in terms of the
		exact type of presentation that they have. Thus, what we want is a
		sequence of imperfect learning objects that together maximize the
		educational performance. We do not know what the order should be, given
		that the order is a matter of pedagogy and not knowledge engineering.
		And even if we were able to fully specify the right pedagogical order
		for each type of student perfectly. We would still not have the
		required information about these learning objects, or the information
		might be wrong. In conclusion, we are learning a sequence of black
		boxes of which we only know that they attempt to teach a particular
		knowledge component, or so they say.
	\item The only way we can measure the value of a particular sequence for a
		group of students, and thereby assess its fitness, is to look at the
		gain in knowledge as observed by the post-test.
	\item More precisely the fitness function is the normalized learning gain
		between the pre-test and post-test for a given knowledge component.
	\item The observed fitness is probably not the same each time a chromosome
		is evaluated. This is due to the fact that students are not identical,
		especially not given the coarse division into four groups. A solution
		is to see the fitness as a stochastic variable that has some noise on
		top of the ``true'' value. In order to obtain an estimate of this true
		value, several approaches are possible. The most simple one is to take
		multiple samples and average over them. However, in this case, taking
		samples must be considered to be expensive. The approach taken must
		therefor try to minimize the number of samples while maximizing the
		certainty of the fitness value.
	\item According to \citet{Jin2005}, fitness inheritence is a popular approach for evolutionary approximation. In fitness inheritence a child inherits some of the fitness information of its parents.
		% From: A comprehensive survey of fitness approximation
		%  in evolutionary computation. By: Y. Jin (2005)
		% Chen J-H, Goldberg DE, Ho S-Y, Sastry K (2002) Fitness
		%  inheritance in multi-objective optimization.
		% Sastry K, Goldberg DE, Pelikan M (2001) Don’t evaluate,inherit.
		% Smith R, Dike B, Stegmann S (1995) Fitness inheritance in
		%  genetic algorithms
		% Zhang X, Julstrom B, Cheng W (1997) Design of vector
		%  quantization codebooks using a genetic algorithm
	\item The following components can be put in the fitness function:
		\begin{itemize}
			\item linear combination of fitness values of the two parents that
				had crossover applied to it. The weights could be determined on
				the portion of the parent that ended up in the child and the
				uncertainty of the fitness value of that parent.
			\item the uncertainty of the fitness value based on how many times
				it was observed, the variation of those observations and a
				linear combination of the uncertainty values of the parents
				plus some constant uncertainty bonus.
			\item 
		\end{itemize}
\end{itemize}
\subsection{Population}
\begin{itemize}
	\item A population of individual chromosomes evolves over generations
	\item Size: 10?
	\item Requirements:
		\begin{enumerate}
			\item Chromosomes need to necessarilly be unique in the
				population. Reasons for not forcing uniqueness
				\begin{itemize}
					\item The initial population size is probably bigger than
						the gene pool of most knowledge components. That means
						that probably the first population already has to be a
						multiset, or it will be smaller than other generations.
					\item The exploration vs exploitation tradeoff states that
						you should also not focus too much on exploration. If
						you would only go for unique chromosomes in each
						generation than that would be mean that the best
						solution is only presented to one student. The others
						could get suboptimal solutions, even if we know that is
						the case. Of course you need to explore, even
						suboptimal solutions. But maybe this should be more
						stochastic than deterministic.
				\end{itemize}
		\end{enumerate}
	\item After having evaluated each member of a generation, a new generation
		is formed.
	\item Certain chromosomes are kept as is, due to the implementation of elitism
		[1 or 2 I think?]
	\item The other chromosomes have a certain probability of surviving. (see
		section~\ref{sec:approach_survivor_selection}.
	\item From the surviving chromosomes, some parents are selected to produce
		offspiring. See section~\ref{sec:approach_parent_selection}.
	\item The offspring is produced according to a set of combination operators
		on the chromosomes of each parent pair. The combination operators have
		a certain probability to be picked. See
		section~\ref{sec:approach_combination_operator}.
	\item The new offspring and old survivors have a certain probability of
		mutation occuring which results in a slightly different individual. See
		section~\ref{sec:approach_mutation_operator}.
	\item Point to a picture depicting the percentages of each population that
		came from elitism, survival, cross-over, mutation. Vertical bar, split
		up into several sections with different colors.
\end{itemize}
\subsection{Parent selection}
\label{sec:approach_parent_selection}
\begin{itemize}
	\item Individuals are selected as parents with a probability proportional
		to their fitness.
\end{itemize}
\subsection{Combination operator}
\label{sec:approach_combination_operator}
\begin{figure}[ht!]
	\centering
	\includegraphics[width=\linewidth]{images/crossover_operations.pdf}
	\caption[Crossover operations]{Crossover operations. \textbf{Note:} Image
is still wrong. a) combination results in two children by combining parent 1
with parent 2 and the other way around, b) it makes more sense to count from
the beginning in one parent and from the end in the other than counting from
the beginning in both. Now it is impossible to take the end of parent 2 and
append it to parent 1 and c) maybe this is also not the best way to show,
perhaps just display an example cut point and only the two resulting children}
	\label{fig:crossover_operations}
\end{figure}
\begin{itemize}
	\item Refer to Figure~\ref{fig:crossover_operations} as a enumeration of
		all possible crossover results for a given example of two parents
	\item Describe the crossover operations formally
		\begin{itemize}
			\item Pick Parent 1 based on fitness PDF
			\item Pick Parent 2 based on fitness PDF, other than Parent 1
		\end{itemize}
	\item Describe the probability distribution
\end{itemize}
\subsection{Mutation operator}
\label{sec:approach_mutation_operator}
\begin{itemize}
	\item Perhaps not real mutation, since that is often only referred to as a
		completly random unbiased change. This can result in invalid outcomes.
	\item The mutation, or otherwise unary, operator in this thesis
		(uniformly?) selects a mutation from a set of possible changes that result
		in valid and unique outcomes.
	\item The mutation operators include:
		\begin{enumerate}
			\item Randomly swapping the group gene of the chromosome with a
				different group gene from the pool. In such a way that the
				resulting chromosome is not already present in the population.
			\item Randomly swapping a resource gene of the chromosome with a
				different resource gene from the pool. In such a way that the
				resulting chromosome is not already present in the population.
			\item Randomly swap the positions of two resource genes in the
				chromosome. While still obaying the uniqueness condition of the
				population.
			\item Randomly removing one resource gene from the chromosome.
			\item Randomly adding one resource gene from the pool to the
				chromosome without introducing duplicates
		\end{enumerate}
\iend{itemize}
\subsection{Survivor selection}
\label{sec:approach_survivor_selection}
\begin{itemize}
	\item Factors that should influence the probability of a candidate to be a
		survivor are:
		\begin{itemize}
			\item The observed fitness
			\item The uncertainty of the fitness value. More uncertain values
				should get more chance of being selected for a new generation
			\item Some linear combination of the teacher ratings for each
				individual learning objects.
			\item Elitism: the best performing organisms are transfered to the next generation unaltered.
		\end{itemize}
\end{itemize}
\subsection{Initialization}
The first generation of the population is initialized with a fixed number of
individuals. Each individual contains a chromosome with exactly one gene. The
individuals are generated according to the following steps:
\begin{enumerate}
	\item For all genes in pool:
		\begin{enumerate}
			\item If population is full, stop
			\item Else, add an individual with the chromosome that contains only that gene.
		\end{enumerate}
	\item While there is room left in the population:
		\begin{enumerate}
			\item \label{init_sample_step}Select a gene according to some probability density function
			\item Add an individual with the chromosome that contains only that
				gene
		\end{enumerate}
\end{enumerate}
The probability density function (PDF) refered to in
step~\ref{init_sample_step} is a uniform distribution by default, but can also
represent apriori values of resources as described in
\ref{sec:approach_bootstrapping}.
\subsubsection{Bootstrapping}
\label{sec:approach_bootstrapping}
% Should this be mentioned, since it has not been used in the experiment?
Some of the OER repositories allow for teachers to give ratings for educational
material. These ratings could be used as an apriori probability that the
material is good. However, only a part the collection of materials will be
rated. Therefore, educational material that does not have a rating is assumed
to be rated neutral (i.e. the middle of a five-point scale).
% Each rating is an average given the number of raters. This number of raters should have impact on the value of the rating.
% Weighted ratings could work even better if the ratings are normalized with an average value of zero, resulting in a symmetrical scale of positive and negative values.
\subsection{Termination condition}
Given the inherent noise in the fitness values, the algorithm should not stop
before the fitness of each possible\footnote{i.e. all possible sequences given
the constraints on length and the uniqueness requirement} chromosome is determined
with some certainty. That would seem to lead to a valid point of termination
when all chromosomes are tried are evaluated with enough certainty. However,
the pool of genes is assumed to grow (i.e. new educational resources are made
available) and each time a new gene is introduced it theoretically needs to be
tried out in every combination with the already existing genes before the valid
termination point would be reached. This would mean that the algorithm would
never terminate, as it should wait for new genes to arrive. If it is vital that
the algorithm finishes, a practical approach could be to stop if the fitness of
one or more individuals is within a small margin of the optimal value. Provided
an optimal value can be defined.

The application presented in this thesis does not require the genetic algorithm
to terminate. The web-based variation to the algorithm described in
section~\ref{sec:web-based_ga} ensures that computation only happens on a event
basis. Furthermore, due to the nature of the application, it is not
as interesting to have the best solution at the end as it is to select the best
known solution at each point that an individual is tested. Naturally a
exploration-explotation trade-off applies where occassionally individuals need
to be tried out that could both be better or worse. So instead of termination,
moving towards convergence is important.
\section{Discussion}
\label{approach_discussion}
\subsection{Benefits of the approach}
\begin{itemize}
	\item More natural fit to the problem of curriculum sequencing, given the
		natural mapping of chromosomes and genes to the domain.
	\item The method is good for changing environments (citation needed)
	\item No need to explitely specify intermediate states
	\item Domain allows for many enhancements of the canonical algorithm by
		adding prior knowledge in the initialization and fitness function, by
		propagating fitness information to next generations using fitness
		inheritance, and restrict the crossover and mutation operations to
		ensure only valid and interesting outcomes.
	\item Search through the solution space is biased towards areas that seem
		most promising, with a small but nonzero chance of exploring in other
		areas.
	\item This implicit exploration-exploitation trade-off can be enhanced by
		incorperating uncertainty information
\end{itemize}
\subsection{Downsides of the approach}
% risk of Hamming walls
\subsection{Comparing with the Markov Decision Process Approach}
\begin{itemize}
	\item Paraphrase/quote/link from \citep{Whiteson2012} the following points.
		(\textbf{Currently copied literally}, better not keep it that way)
	\item evolutionary methods do not take advantage of the fact the an agent travels
          to states while performing actions. However evolutionary computation
		  is still a popular method for solving reinforcement learning
		  problems. There are three main reasons why.:
		  \begin{enumerate}
			  \item ``First, evolutionary methods can cope well with
					partial observability. While evolutionary methods do not exploit the relationship
					between subsequent states that an agent visits, this can be advantageous when the
					agent is unsure about its state. Since temporal-difference methods rely explicitly
					on the Markov property, their value estimates can diverge when it fails to hold,
					with potentially catastrophic consequences for the performance of the greedy policy.
					In contrast, evolutionary methods do not rely on the Markov property and will always
					select the best policies they can find for the given task. Severe partial
					observability may place a ceiling on the performance of such policies, but
					optimization within the given policy space proceeds normally (Moriarty et al, 1999).
					In addition, representations that use memory to reduce partial observability,
					such as recurrent neural networks, can be be optimized in a natural way with
					evolutionary methods (Gomez and Miikkulainen, 1999; Stanley and Miikkulainen, 2002;
					Gomez and Schmidhuber, 2005a,b).``
				\item ``Second, evolutionary methods can make it easier to find
					suitable representations for the agent’s solution. Since policies need only specify
					an action for each state, instead of the value of each state-action pair, they can be
					simpler to represent. In addition, it is possible to simultaneously evolve a
					suitable policy representation``
				\item ``Third, evolutionary methods provide a simple way to solve
					problems with large or continuous action spaces. Many temporal-difference
					methods are ill-suited to such tasks because they require iterating over the action
					space in each state in order to identify the maximizing action. In contrast,
					evolutionary methods need only evolve policies that directly map states to actions. Of
					course, actor-critic methods (Doya, 2000; Peters and Schaal, 2008) and other techniques
					(Gaskett et al, 1999; Mill ́an et al, 2002; van Hasselt and Wiering, 2007) can
					also be used to make temporal-difference methods suitable for continuous action
					spaces. Nonetheless, evolutionary methods provide a simple, effective way to
					address such difficulties.``
				\item \citet{Whiteson2012} further mentions: ``Of course, none
					of these arguments are unique to evolutionary methods, but
					apply in principle to other policy-search methods too.
					However, evolutionary methods have proven a particularly
					popular way to search policy space and, consequently, there
					is a rich collection of algorithms and results for the
					reinforcement-learning setting. Furthermore, as modern
					methods, such as distribution-based approaches, depart
					further from the original genetic algorithms, their
					resemblance to the process of natural selection has
					decreased. Thus, the distinction between evolutionary
					methods and other policy search approaches has become
					fuzzier and less important.''
		  \end{enumerate}
\end{itemize}
\subsection{Comparing with the Knowledge Engineering Approach}
