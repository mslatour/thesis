%%%%%%%%%%%%%%%%%%%%%
% Chapter: Approach %
%%%%%%%%%%%%%%%%%%%%%

\section{The Genetic Algorithm}
This section provides a brief introduction into genetic algoritms. The purpose
of this section is to establish a shared understanding of the standard setup. For a more
in-depth introduction, the reader is referred to \citep{Eiben2007}.\\\\
\noindent
The \emph{genetic algorithm} \citep{Holland1992} is a part of a family of
search algorithms called \emph{evolutionary computing}. The technique draws
inspiration from Darwinian evolution and naturual selection. In genetic
algorithms, a population of individuals evolves over multiple generations to
better perform on some metric. These individuals all have a set of traits that
influence their performance. For example, a bird could have traits like a long
tail or bright colors. Traits are caused by certain genes. A particular
configuration of genes is called a chromosome. Individuals that perform better
than others have a higher chance of survival. The new generation contains the
offspring of the individuals that survived. The offspring inherits the
chromosomes of their parents. That way, traits that have a positive influence
on performance have a higher chance of ending up in new individuals. Surviving
individuals pair up with others to form a set of two parents. The resulting
offspring inherits a combination of the chromosomes of both parents. Usually
two parents form two new individuals. This application of the \emph{survival of
the fittest} results in more individuals with successful traits and less
individuals with unsuccessful traits.\\\\
\noindent
The peppered moth, the most cited example of Darwinian evolution
\citep{Majerus2009}, illustrates this perfectly. The peppered moth rests during
the day on the trunk of particular trees. At that moment birds pray on the
moths. The color of the peppered moth is originally light gray. This trait
camouflages them fairly well against the light bark of the trees. In other
words, the fitness of these white moths is higher than moths of a different
color. As a result most peppered moths had a light color.
However, that all changed during the industrial revolution. The industrial
revolution caused polution in the air that blackend the bark of the trees. As a
result, the white peppered moths were easily spotted by praying birds. A
variation of the peppered moth, with a dark color, suddenly had a better
camouflage against the dark trunks. The black-bodied peppered moth produced
more offspring because their increased chance of survival. As a result the
occurence of dark peppered moths rose significantly.
In modern times, the air is much cleaner and the color of the bark of the trees
became light again. As a result the dark peppered moths were at a disadvantage.
The frequency of light peppered moths rose to be the large majority once
again.\\\\
\noindent
New variations like the dark peppered moths, are caused by genetic mutations. A
mutation is a copying error of the chromosome during inheritence. The
mutated chromosome causes traits that could benefit an individual's chance of
survival. In that case the mutated chromosome will occur more often in new
generations of the population. As was the case in the example of the peppered
moths.\\\\
The genetic algorithm uses the same approach to find optimal solutions in a
large space of possibilities. In our case, finding the optimal sequence of OER.
A particular application of this algorithm designs counterparts of the
components of the natural selection mechanism. The components that need to be
designed are briefly discussed in the the rest of this section. The standard
genetic algorithm follows roughly the following steps \citep{Eiben2007}.
\begin{leftbar}
\smallskip
\noindent
\textbf{Genetic Algorithm Outline}
\begin{enumerate}
	\item Initialization
	\item Evaluation of each candidate
	\item Repeat until termination condition is satisfied:
		\begin{enumerate}
			\item Parent selection
			\item Recombination of parent pairs
			\item Mutation of the resulting offspring
			\item Evaluation of each candidate
			\item Survivor selection
		\end{enumerate}
\end{enumerate}
\end{leftbar}
\subsection{Representation of the domain}
The \emph{phenotype} is the collection of properties of an individual, such as
a long tail or color. The \emph{genotype} is the genetic information that
causes those properties. In order words, the chromosome containing particular
genes represents the aforementioned properties in genetic terms. This
distinction is important for genetic algorithms, as it is often the case that
there is a translation necessary between the two. Arguably, one of the first
tasks in applying a genetic algorithm is finding a translation of your
solution space to a genetic encoding.\\\\
\noindent
The standard encoding is the \emph{binary encoding}, where chromosomes are encoded as
strings of 1's and 0's. This encoding allows for simple mutation and crossover
operators that work on the bit level. However, for many problem types this can
result in invalid individuals. Other encodings have been developed to improve
this.\\\\
\noindent
For example, suppose we want a genetic algorithm to work on the travelling
salesman problem. In this problem, the salesman needs to find the shortest
route through all cities. Each solution to this problem would be some
travelling plan that enumerates cities in the order that the saleman should
visit them \textit{(phenotype)}. This could be encoded as an ordered list of
numbers, where each number represents a city \textit{(genotype)}. This encoding
is known as the integer or \emph{permutation encoding}. In the field of
curriculum sequencing, the permutation encoding is also widely used
\citep{AlMuhaideb2011}.
\subsection{Candidate evaluation}
Individuals, carrying a particular chromosome, are exposed to the environment.
This environment determines the chance of survival of the individuals, and
thereby of their chromosomes. In the peppered moth example, the bark of the
tree's trunk determines the survival chance of each individual moth. This
survival chance, due to how well the individual fits its environment, is
expressed by the fitness value. In more abstract terms, the fitness value
expresses how good the found solution is. The fitness function can calculate
these values for an arbitrary individual.\\\\
\noindent
The example of the travelling salesmen has an obvious candidate. The fitness
function could measure the distance travelled in the proposed travelling plan.
Although in this particular example, you would want the distance to negatively
correspond to the survival chance.\\\\
\noindent
The selection of individuals to evaluate is done uniformly in the basic
implementation. In domains where the fitness function is deterministic, each
individual is evaluated once. In more noisy domains there is a larger number of
evaluations that can be divided over the individuals uniformly in each
generation.
\subsection{Population}
A population of individuals goes through several generations. Each generation
is a new step in the search for the optimal solution. The initialization of a
population is usually done by random sampling of chromosomes for its
individuals. An important property is the number of individuals in each
generation. Usually this number is fixed to one number, but it can also vary.
The number of individuals is important as it determines the capacity for
variation in one generation. The population is however a multiset. This means
chromosomes can be contained by multiple individuals. Therefore it is also
relevant to look at the diversity in the generation.\\\\
\noindent
The standard implementation of a genetic algorithm needs to terminate. One
obvious candidate for a termination condition is when the algorithm found an
optimally performing individual. In other words, when the fitness of the
individual is, within a small range of, the maximum possible value. However,
there are no guarantees that the genetic algorithm would reach this point.
Other termination conditions can be added to deal with this. One example is to
stop after a fixed number of evaluations.
\subsection{Evolution}
\label{sec:approach_intro_evolution}
Searching occurs in genetic algorithms by means of evolution. There are three
important stages in this evolution. First parent pairs are selected from the
survivors. The chromosomes of these parents are then recombined into two new
chromosomes. After the recombination, mutation may take place on the resulting
chromosomes. At the end, the two new chromosomes end up in the new generation.
The three stages are further clarified in the next subsections.
\subsubsection{Parent Selection}
When all fitness evaluations have been made, some chromosomes will be selected
to become a parent. Parents are selected in pairs, in order to let their
chromosomes recombinate. This selection of parents is at least based on the
fitness of the chromosomes. However, also other features such as a chromosome's
age may influence the selection. There are also various ways in using these
values for selection. One is \emph{tournament selection}, where individuals
compete against each other and the one with the highest fitness wins. Another
is \emph{ranking selection}, where the probability of a chromosome being
selected is proportionate to its rank in fitness values. A common selection
method is \emph{roulette wheel selection} or \emph{fitness-based selection}.
This is a sampling method where the fitness value is proportionate to the
probability of being sampled. The roulette wheel is a circle divided in a
number of segments. Each segment corresponds to an individual. The size of the
segment is proportionate to the fitness value of the individual. A random
position on the circle is chosen. The segment that contains this position
corresponds to the individual selected.
\subsubsection{Recombination}
Recombination is responsible for combining information from two chromosomes.
This recombination occurs by a crossover operator. There many different
possible crossover operations. Two common ones are \emph{one-point crossover}
and \emph{two-point crossover}. The one-point crossover splits the chromosomes
at the same random point. The resulting four halfs are recombined in the
alternative way, while maintaining their position in the chromosome.
Figure~\ref{fig:single_point_crossover} illustrates the splitting of two parent
chromosomes and their recombination into two child chromosomes.\\
\begin{figure}[h]
	\centering
	\includegraphics[width=0.5\linewidth]{images/single_point_crossover.pdf}
	\caption{Example of a single-point crossover operation}
	\label{fig:single_point_crossover}
\end{figure}\\
\noindent
The two-point crossover splits the chromosomes at two points. The segment of
genes between the two split points in both both chromosomes is swapped.
Figure~\ref{fig:two_point_crossover} illustrates the application of the
two-point crossover.\\
\begin{figure}[h]
	\centering
	\includegraphics[width=0.5\linewidth]{images/two_point_crossover.pdf}
	\caption{Example of a two-point crossover operation}
	\label{fig:two_point_crossover}
\end{figure}%\\
%\noindent
%Schema theorem\ldots
\subsubsection{Mutation}
Selection and recombination steer the search towards the part of the search
space that appears to be most promising. As a result, parts of the search space
might never be reached and evaluated. There is no guarantee that this steering
will converge to an optimal solution. This is especially true when the initial
population does not hold the necessary variation. Therefore, most genetic algorithm
implementations also include mutation. The mutation operator introduces random
changes to chromosomes when passed through from parents to offspring. In the
standard binary encoding of genes in a chromosome, the basic mutation operator
flips a random bit. The permutation encoding facilitates a swap mutation, where
to random positions in the chromosome are swapped.\\\\
\noindent
Although mutations can be vital for performance, it is still a disruption. Too
much mutation will prevent convergence. Mutation is therefore usually only
applied with a very low probability. The mutation operator is applied after
recombination took place.
\subsubsection{Survivor selection}
Populations often have a fixed size. The newly created offspring together with
the existing population forms a group of candidates that exceeds this size. In
the survivor selection step, the members of the new generation are selected
from these candidates. Unlike the parent selection, which is stochastic, the
survivor selection is often deterministic. An example selection method is to
just take the top $n$ chromosomes in order of their fitness. Another common
method is \emph{generational replacement}. In this method, the chromosomes in
the generation are completely replaced by their offspring.
\subsection{Extensions}
Several extensions have been proposed to the standard genetic algorithm. Two of
them are relevant for this thesis. They will be briefly explained.
\subsubsection{Elite preservation}
Although mutation ensures that every chromosome is theoretically reachable.
However, the probability of this happening might be very small. In a finite
number of generations there is no guarantee that the optimal solution will be
found. There is furthermore no guarantee that good solutions will be kept in
the population. Elitism, or \emph{elite preservation}, ensures that the $n$
best individuals of each generation are transferred to the next one. Elite
individuals are not subjected to crossovers or mutation. Nor are they dependant
on stochastic sampling. The number of elite individuals must be kept small.
Otherwise the genetic algorithm will no longer have enough individuals to evolve.
\subsubsection{Island model}
In the island model, a population is split up in separate subpopulations,
called \emph{demes}. These demes evolve independantly from each other.
However, periodically communication can occur through \emph{migration} of
individuals. The approach is a form of parallelisation and works particularly
well when a problem consists of linearly separable subproblems
\citep{Whitley1999}.\\\\
\noindent
According to \citep{Nowostawski1999}, the island model is controlled by
four parameters. These are the \emph{topology}, the \emph{migration interval}, the
\emph{migration scheme} and the \emph{migration size}. The \emph{topology}
determines which demes are connected, which allows for migration. The
\emph{migration interval} determines the number of generations between a
migration. The \emph{migration scheme} determines which individual is picked
from the source deme: the worst, the best or a random individual. It also
determines which individual is replaced at the target deme: the worst, the best
or a random individual. Replacement only occurs if the migrating individual has a higher fitness. The \emph{migration size} determines how many individuals are
exchanged during each migration. For a more extensive analysis of the island model in genetic algorithms the reader is referred to \citep{Martin1997} and \citep{Whitley1999}.

%%%%
% Representation/Domain modeling
%%%
\section{Modeling of the genetic algorithm}
This section describes the way in which the task described in
Chapter~\ref{ch:curriculum_sequencing} is modeled using genetic algorithms.
Each section discusses an important aspect of the modeling: representation
(Section~\ref{sec:approach_representation}), initialization
(Section~\ref{sec:approach_initialization}), termination conditions
(Section~\ref{sec:approach_termination}), fitness
(Section~\ref{sec:approach_evaluation}) and parent selection, variation
operators and survivor selection
(Section~\ref{sec:approach_generation_switch}). The applied island model to
support for related student groups is described in
Section~\ref{sec:approach_island_model}.

\subsection{Representation of the domain}
\label{sec:approach_representation}
The \emph{permutation encoding} is used to represent each
sequence. However, unlike most curriculum sequencing approaches
\citep{AlMuhaideb2011}, the chromosomes have variable length. The variable
length is necessary because the OER sequences have variable length as well.
Chromosomes can furthermore also be partial permutations, where not all OER are
contained in the sequence.
%%%
% Initialization
%%%
\subsection{Population}
\subsubsection{Initialization}
\label{sec:approach_initialization}
The population is not initialized purely randomly. Instead, the first
generation contains only sequences with exactly one gene. This is to introduce
a bias towards smaller sequences. The individuals are generated according to
the following steps:
\begin{enumerate}
	\item For all resources in pool:
		\begin{enumerate}
			\item If population is full, stop
			\item Else, add an individual with the chromosome that contains
				only that resource.
		\end{enumerate}
	\item While there is room left in the population:
		\begin{enumerate}
			\item \label{init_sample_step}Select a resource according to some probability density function
			\item Add an individual with the chromosome that contains only that
				resource
		\end{enumerate}
\end{enumerate}
The probability density function (PDF) refered to in
step~\ref{init_sample_step} is a uniform distribution by default, but can also
represent apriori weights of resources.
%%%
% Termination
%%%
\subsubsection{Termination}
\label{sec:approach_termination}
Given the inherent noise in the fitness values, the algorithm should not stop
before the fitness of each possible\footnote{i.e. all possible sequences given
the constraints on length and the uniqueness requirement} chromosome is determined
with some certainty. That would seem to lead to a valid point of termination
when all chromosomes are evaluated with enough certainty. However,
the pool of resources is assumed to grow (i.e. new educational resources are made
available) and each time a new resource is introduced it theoretically needs to be
tried out in every combination with the already existing resources before the valid
termination point would be reached. This would mean that the algorithm would
never terminate, as it should wait for any new resources to arrive. If it is vital that
the algorithm finishes, a practical approach could be to stop if the fitness of
one or more individuals is within a small margin of the optimal value. Provided
an optimal value can be defined.\\\\
\noindent
The application presented in this thesis does not require the genetic algorithm
to terminate. The web-based variation to the algorithm described in
Section~\ref{sec:web-based_ga} ensures that computation only happens on a event
basis. Furthermore, due to the nature of the application, it is not
as interesting to have the best solution at the end as it is to select the best
known solution at each point that an individual is tested. Naturally a
exploration-explotation trade-off applies where occassionally individuals need
to be tried out that could both be better or worse. So instead of termination,
moving towards convergence is important.

%%%
% Candidate evaluation
%%%
\subsection{Candidate evaluation}
\label{sec:approach_evaluation}
%%%
% 	Fitness function
%%%
\subsubsection{Fitness function}
% From: A comprehensive survey of fitness approximation
%  in evolutionary computation. By: Y. Jin (2005)
% Chen J-H, Goldberg DE, Ho S-Y, Sastry K (2002) Fitness
%  inheritance in multi-objective optimization.
% Sastry K, Goldberg DE, Pelikan M (2001) Donâ€™t evaluate,inherit.
% Smith R, Dike B, Stegmann S (1995) Fitness inheritance in
%  genetic algorithms
% Zhang X, Julstrom B, Cheng W (1997) Design of vector
%  quantization codebooks using a genetic algorithm
Learning objects are often not a perfect fit. They might explain too much or too
little about some context. On top of that, it is not that well indexed in terms of the
exact type of presentation that they have. Thus, what we want is a
sequence of imperfect learning objects that together maximize the
educational performance. We do not know what the order should be, given
that the order is a matter of pedagogy and not knowledge engineering.
And even if we were able to fully specify the right pedagogical order
for each type of student perfectly. We would still not have the
required information about these learning objects, or the information
might be wrong. In conclusion, we are learning a sequence of black
boxes of which we only know that they attempt to teach a particular
knowledge component.\\\\
\noindent
The only way we can measure the value of a particular sequence for a
group of students, and thereby assess its fitness, is to look at the
gain in knowledge as observed by the post-test. More precisely the fitness
function used in this thesis is the normalized learning gain between the
pre-test and post-test for a given knowledge component, given by $\frac{C^2 -
C^1}{1-C^1}$ where $C^1$ and $C^2$ represent the percentage of correct answers
on the pre-test and post-test respectively of the student.\\\\
\noindent
The observed fitness is probably not the same each time a chromosome
is evaluated. This is due to the fact that students are not identical,
especially not given the coarse division into student groups. A solution
is to see the fitness as a stochastic variable that has some noise on
top of the ``true'' value. In order to obtain an estimate of this true
value, several approaches are possible. The most simple one is to take
multiple samples and average over them. However, in this case, taking
samples must be considered to be expensive. The approach taken must
therefore try to minimize the number of samples while maximizing the
certainty of the fitness value. Which is why Upper Confidence Bound selection
was applied in this thesis, as described in Section~\ref{sec:approach_ucb}.

%%%
%   UCB-1 selection
%%%
\subsubsection{UCB Selection}
\label{sec:approach_ucb}
In this thesis, the Upper Confidence Bound (UCB) selection algorithm is used to
determine which of the individuals will be evaluated. In
particular the UCB-1 \citep{Auer2002} algorithm is used. In UCB-1,
first every individual is evaluated once. After this has been done, the
individual is evaluated for which equation~\eqref{eq:ucb1_value} is maximized,
where $\overline{x_i}$ denotes the average fitness of the individual, $n_i$
denotes the number of times the individual has been evaluated so far and $n$
denotes the overal number of evaluations that occured.\\
\begin{equation}
	\overline{x_i} + \sqrt{\frac{2 \ln n}{n_i}}
	\label{eq:ucb1_value}
\end{equation}\\
\noindent
UCB-1 is proven in \citep{Auer2002} to logarithmically bound the
regret, which ensures that a suboptimal individual is selected logarithmically
less often than the optimal individual. It is important to note that UCB-1 can
only consider the individuals that are present in the current generation of the
population for which the evaluation occurs. This means that there is some
interplay between the UCB-1 mechanism and the selection mechanism of the
genetic algorithm, where the genetic algorithm is responsible for searching
through the solution space efficiently and the UCB-1 algorithm is responsible
for reducing the regret.

%%%
% Generation switch
%%%
\subsection{Evolution}
\label{sec:approach_generation_switch}
%%%
%  	Parent selection
%%%
\subsubsection{Parent selection}
\label{sec:approach_parent_selection}
Parents are selected in pairs using \emph{roulette wheel selection}. If the number of
individuals in the population is odd, there will be one parent remaining after
all pairs have been formed. That parent's chromosome is then added to the new
generation as its own offspring.
%%%
%  	Crossover operation
%%%
\subsubsection{Combination operator}
\label{sec:approach_combination_operator}
When two parents are matched to create offspring, their chromosome's are
combined using a crossover operation. The resulting chromosome is placed in a
new individual. There are two crossover operations implemented for this thesis:
\emph{one-point crossover} and \emph{append crossover}.

\paragraph{One-point crossover} The one-point crossover operation is typically
implemented by picking one point for both parents to split, after which the
four halfs are recombined into two new children. The individuals in this
thesis, however, can vary in length. That means that crossover points could be
selected that do not exist in both parents. Naturally one could restrict the
set of valid crossover points to be within the boundaries of both chromosomes.
However, that would also limit valid chromosomes, even though they can be
achieved by combining both parent chromosomes.\\\\
\noindent
In this thesis, the one-point crossover operator is implemented differently.
Instead of picking one point for both parents at once, one crossover point in
each parent is randomly picked independent from the other. These two crossover
points then split up both parents in two pieces each, allowing for the
formation of two new children after recombination. The implementation ensures
that only valid children are the result of the operation. When no valid
children can be created, the one-point crossover is skipped and the append
crossover is attempted.

\paragraph{Append crossover} The append crossover was designed for the edge
case where two parents cannot be split up and recombined into two new valid
children. For example when one or both parents have a chromosome with one gene,
which is impossible to split up. The append crossover operator simply appends
one parent after the other. The two ways to do this result in two children.

%%%
%  	Mutation operation
%%%
\subsubsection{Mutation operator}
\label{sec:approach_mutation_operator}
In this thesis three different mutation operators have been
applied: \emph{swap mutation}, \emph{addition mutation}, \emph{deletion mutation}.

\paragraph{Swap mutation} The standard swap mutation for permutations is used.
The chromosome needs to contain at least two genes in order to be applied to
this mutation. If this is not the case, a different mutation is attempted.

\paragraph{Addition mutation} The chromosome applied to the addition mutation
operator will be appended with a new gene from the gene pool. The gene that is
added must not already exist in the chromosome. If no gene can be selected from
the pool that satisfies this constraint, a different mutation is attempted.

\paragraph{Deletion mutation} The deletion mutation operation deletes a random
gene from the chromosome, resulting in a shift in position of the genes after
it. The resulting chromosome must have at least one gene left. If this is not
possible, a different mutation is attempted.

\subsubsection{Survivor selection}
\label{sec:approach_survivor_selection}
This thesis implements generational replacement with elite preservation, which
are commonly used strategies for survivor selection in the curriculum
sequencing domain \citep{AlMuhaideb2011}.

%%%
% Island model
%%%
\subsection{Island model}
\label{sec:approach_island_model}
Section~\ref{sec:task_student_groups} described how the sequencing task is done
per student group and per knowledge component. Each combination is represented
as separate populations. However, the populations that represent the same
knowledge component but different student groups co-evolve.\\\\
\noindent
The island model was used to model exchange of information between
related populations. The migration scheme is set to migrate the best individual
of the source population and replace the worst individual in the target
population. This occurs at every new
generation. The migrated individuals are copies, and do not change the
occurrence of the migrated chromosomes in the source population. The topology
links populations of the same knowledge component together. Only one individual
is migrated per generation.\\\\
\noindent
Important to note is that all other actions of the genetic algorithm in each
population are still independent, meaning that the populations can also evolve
at different speeds. As a consequence, a population that evolves really slowly
will continue to migrate the same individual towards the target population.
Even if it turned out not to work well. To counter this, the migrating
individual of the source population competes with the worst individual in the
target population through roulette selection. If the fitness of the migrating
individual is worse than the worst individual in the target population, the
replacement is not likely to proceed.
