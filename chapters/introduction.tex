%%%%%%%%%%%%%%%%%%%%%%%%%
% Chapter: Introduction %
%%%%%%%%%%%%%%%%%%%%%%%%%
Open Educational Resources (OER) are a well-studied topic in communities of
scientists \citep{Wiley2014, Hylen2012, Duval2010}, practitioners
\citep{Johnson2013, Yuan2013, Trendsurfoe2014} and policy-makers
\citep{Bussemaker2014,OECD2007}. In addition to standard learning objects
\citep{McGreal2004}, OER are free to be reused, revised (i.e. altered), remixed
(i.e. combined with others) and afterwards redistributed \citep{Hilton2010}. As
a consequence the threshold for innovation of education material is lowered.
This results in a less stable quality level of the shared learning objects due
to a larger diversity in authors \citep{Weller2010}.\\\\
\noindent
The selection of OER from repositories and the subsequent determination of the
quality are particularly dependent on actions of instructors. \citet{Ochoa2009a}
show that the size of OER collections vary from hundreds to
millions of objects depending on the type of repository. \citeauthor{Ochoa2009a}
expect that exponential growth will occur when the repositories are capable of
retaining its productive users. Determining the quality of an exponentially
growing number of open educational resources by human effort is infeasible
\citep{Cechinel2011, Ochoa2006, Zemsky2004}. Acquiring a reliable automatic
method for assessing OER quality is thus required.\\\\
\noindent
Previous approaches have predominantly focussed on proxies of OER quality. Some
automatically evaluated the quality of metadata \citep{Ochoa2009b, Tani2013}.
\citet{Cechinel2011, Cechinel2012} took a different approach by predicting quality ratings of
learning objects based on intrinsic metrics (e.g. number of links in a
document). \citet{Duval2006} proposed the context-dependent ranking algorithm
LearnRank, where learning objects that are used in many contexts receive a
higher rank. In \citep{Ochoa2006} the attention given to an OER is taken as a
proxy for its usefullness.\\\\
\noindent
A recent report from the European Commission on the quality issue of OER
identified one of the challenges to be that educational resources of high
quality are fragmented with no particular way of distinguishing them from the
other available learning objects \citep{Camilleri2014}. \citet{Duval2006}
states that in an ideal case empirical data of the learning effect caused by a
particular OER bootstraps its ranking. \citet{Camilleri2014} refers to impact
as one of the five important aspects of OER quality.\\\\
\noindent
However, in the proposed automatic mechanisms to assess OER quality, the impact
a particular OER has on learning has thusfar been mostly neglected
\citep{Kay2007}. This is an undesirable situation as the sole purpose of any
learning material is to have a positive effect on learners. This situation is
particularly unsatisfactory because of the growing demand for evidence-based
teaching decisions using quantitative data \citep{Wayman2005, Marsh2006, Spillane2012, Clow2013}.\\\\
\noindent
A complication with the assessment of OER quality by measured impact is that in
general educational material is sequenced with other educational material
before being presented to students \citep{Brusilovsky1992, Quinn2000}.
Furthermore, the activities before and after an OER also affect its quality
\citep{Duval2006}. It is therefore necessary to determine the quality of an OER
within the sequence it is part of. As a consequence, two issues need to be
taken into account when automatically assessing OER quality. First of all,
there are many OER sequences possible, even when there are only a few OER
available for a particular topic. These sequences will require multiple
evaluations before an estimate of learning impact can be made due to the
inherent noise in the domain. This experimentation clearly does not come
without cost. Each time a sequence shows to be less effective than a different
one, a learner has received a lower level of education than necessary. This
turns OER quality assessment in a curriculum sequencing task
\citep{AlMuhaideb2011} with an \emph{exploration vs. exploitation trade-off}
\citep{Holland1992}. Second of all, repositories are constantly updated with
new OER. The collection of possible sequences of OER will therefore continue to
grow during a quality assessment process. This is known as the \emph{open
corpus} problem \citep{Brusilovsky2007}.\\\\
\noindent
This thesis introduces and evaluates \emph{TutOER}, a novel approach to
automatic assessment of OER quality. \emph{TutOER} estimates the impact of a
sequence of OER by measuring the knowledge level of a student before and after the
sequence is presented to the student. Figure~\ref{fig:assessment_of_sequences}
depicts the situation. The curriculum sequencing task is executed by a genetic
algorithm with generational replacement and elite preservation. Sequences of
OER are evolved by crossover and mutation in order to consider better sequences
over time. The survival chance of an OER sequence is proportional to its
measured impact. The genetic algorithm was extended with UCB-1 selection
\citep{Auer2002} for better cost boundaries.\\\\
\noindent
The \emph{TutOER} system was evaluated in a newly created online course around
the mathematical game Nim. The course contained four lessons through which a
participant was instructed about the game and its winning strategy. Each lesson
contained a sequence of OER that was selected by the \emph{TutOER} system to be
evaluated. Additionally a series of simulations were executed to explore
the behavior of the system in several theoretical situations.\\
\begin{figure}[h!]
	\begin{framed}
	\centering
	\includegraphics[width=0.9\linewidth]{images/assessment_of_sequences.pdf}
	\caption[Setup of assessments of impact OER]{The impact of an OER sequence
		is measured by a knowledge test before and after the
	sequence was presented to the student. The sequence is selected by the
	\emph{TutOER} system.}
	\label{fig:assessment_of_sequences}
	\end{framed}
\end{figure}\\
\noindent
This thesis is structured as follows. Chapter~\ref{ch:background} provides
background information and related work. Chapter~\ref{ch:curriculum_sequencing}
contains a detailed description of the task. The approach is described in
Chapter~\ref{ch:approach} and the resulting software in
Chapter~\ref{ch:software}. In Chapter~\ref{ch:simulations} the simulations are
discussed. Chapter~\ref{ch:experimental_setup} covers the setup
of the experiment. The results of this experiment are discussed in
Chapter~\ref{ch:results}. Chapter~\ref{ch:discussion_conclusion} concludes the
findings in this thesis and provides general discussion.
